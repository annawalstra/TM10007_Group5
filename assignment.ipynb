{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment Group 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "f199da1d-a7c4-450f-9784-2e433c4bcbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/annawalstra/tm10007_Group5.git\n",
        "!pip install simpleITK"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: simpleITK in /usr/local/lib/python3.6/dist-packages (1.2.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9m4YpjyWu6",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-J7kksF-ZT",
        "colab_type": "text"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "b9acf6e5-9c22-463d-fe0e-4d1f70202d3e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550
        }
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "import SimpleITK as sitk\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition\n",
        "\n",
        "# Classifiers and kernels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "\n",
        "\n",
        "# To learn more about metrics see: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "\n",
        "# Data loading functions. Uncomment the one you want to use\n",
        "from adni.load_data import load_data\n",
        "data = load_data()\n",
        "print(f'The number of spamples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Creating X and Y \n",
        "X = data.loc[:, data.columns != 'label']\n",
        "Y = data['label']\n",
        "\n",
        "# Preprocessing: deleting features with only zeros\n",
        "X = X.loc[:, (X != 0).any(axis=0)]\n",
        "# print(f'The number of spamples: {len(X.index)}')\n",
        "# print(f'The number of columns: {len(X.columns)}')\n",
        "\n",
        "# Binarize Y labels\n",
        "y_bin = preprocessing.label_binarize(Y, ['CN','AD'])\n",
        "y_bin = [i[0] for i in y_bin]\n",
        "#print(y_bin)\n",
        "\n",
        "# Split the dataset in train and test part\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y_bin, test_size=0.5, stratify=y_bin)\n",
        "\n",
        "\n",
        "# Scale the data \n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#Fitting the PCA algorithm with our Data\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA().fit(X_train_scaled)\n",
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)') #for each component\n",
        "plt.title('Dataset Explained Variance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Perform a PCA\n",
        "pca = decomposition.PCA(n_components=50)\n",
        "pca.fit(X_train_scaled)\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of spamples: 855\n",
            "The number of columns: 268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[[ 3.74478921e+00  8.05261649e-01 -3.61940934e+00 ... -8.10808893e-01\n",
            "  -1.60918816e+00  9.53393112e-03]\n",
            " [ 5.99432605e+00 -1.14018770e+01  2.35969622e+00 ...  8.93868630e-01\n",
            "   1.44084927e+00 -7.90610016e-01]\n",
            " [-4.09074374e-01 -3.26262731e-01  2.67768653e+00 ... -2.67852889e-01\n",
            "   1.25541543e+00  1.54557867e+00]\n",
            " ...\n",
            " [-4.35621215e+00 -5.56428877e-01  4.75838099e+00 ... -1.81450960e+00\n",
            "   4.20863665e-01 -1.03802326e-02]\n",
            " [-7.47405892e+00 -9.54510095e-01  7.27988255e+00 ... -1.33850090e+00\n",
            "   6.53923135e-01 -7.40392887e-01]\n",
            " [-1.30438639e+00 -6.12509144e+00 -4.54392209e+00 ...  9.15612205e-02\n",
            "  -4.89924295e-01  3.45611611e-01]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgtMEyyJb6BZ",
        "colab_type": "text"
      },
      "source": [
        "## KNN Classifier\n",
        "\n",
        "Vraag: met grid_search.best_estimator_ krijg ik als het beste resultaat k=33, maar als ik k=25 invul krijg ik een hoger resultaat voor test en train. \n",
        "\n",
        "vgm snap ik dit nu wel...Soms grid_search.best_estimator_ ander resultaat voor beste k dan clf.n_neigbors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N-xw5GccCNu",
        "colab_type": "code",
        "outputId": "838a145f-8ee1-40e3-a8bb-148db4179cd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "# Specify the classifier\n",
        "knn = neighbors.KNeighborsClassifier()\n",
        "parameters = {\"n_neighbors\": list(range(1, 51, 2))}\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='accuracy')\n",
        "grid_search.fit(X_train_pca, Y_train)\n",
        "# Show the complete results of the cross validation\n",
        "display(pd.DataFrame(grid_search.cv_results_))\n",
        "\n",
        "\n",
        "# # Fit kNN\n",
        "# Get resulting classifier\n",
        "print(grid_search.best_estimator_)\n",
        "#print(f'Best classifier: k={clf.n_neighbors}')\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors=21)\n",
        "clf.fit(X_train_pca, Y_train)\n",
        "score_train = clf.score(X_train_pca, Y_train)\n",
        "score_test = clf.score(X_test_pca, Y_test)\n",
        "\n",
        "# Get the accuracy\n",
        "y_pred = clf.predict(X_train_pca)\n",
        "acc_train=metrics.accuracy_score(Y_train, y_pred)\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "acc_test=metrics.accuracy_score(Y_test, y_pred)\n",
        "\n",
        "# Print result\n",
        "print(f\"Training result: {score_train}\")\n",
        "print(f\"Test result: {score_test}\")\n",
        "print(f\"Accuracy:\")\n",
        "print(f\"Training result: {acc_train}\")\n",
        "print(f\"Test result: {acc_test}\")"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_neighbors</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001619</td>\n",
              "      <td>0.000265</td>\n",
              "      <td>0.003586</td>\n",
              "      <td>0.000315</td>\n",
              "      <td>1</td>\n",
              "      <td>{'n_neighbors': 1}</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.604651</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.721429</td>\n",
              "      <td>0.073724</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001380</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.003358</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>3</td>\n",
              "      <td>{'n_neighbors': 3}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.742137</td>\n",
              "      <td>0.068279</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001391</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.003374</td>\n",
              "      <td>0.000053</td>\n",
              "      <td>5</td>\n",
              "      <td>{'n_neighbors': 5}</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.763400</td>\n",
              "      <td>0.045323</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001345</td>\n",
              "      <td>0.000015</td>\n",
              "      <td>0.003400</td>\n",
              "      <td>0.000089</td>\n",
              "      <td>7</td>\n",
              "      <td>{'n_neighbors': 7}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.767940</td>\n",
              "      <td>0.049578</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001401</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>0.003504</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>9</td>\n",
              "      <td>{'n_neighbors': 9}</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.770377</td>\n",
              "      <td>0.040646</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.001347</td>\n",
              "      <td>0.000017</td>\n",
              "      <td>0.003410</td>\n",
              "      <td>0.000046</td>\n",
              "      <td>11</td>\n",
              "      <td>{'n_neighbors': 11}</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.798450</td>\n",
              "      <td>0.043944</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.001385</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.003540</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>13</td>\n",
              "      <td>{'n_neighbors': 13}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.791417</td>\n",
              "      <td>0.053133</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.001383</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.003646</td>\n",
              "      <td>0.000185</td>\n",
              "      <td>15</td>\n",
              "      <td>{'n_neighbors': 15}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.786711</td>\n",
              "      <td>0.053187</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001376</td>\n",
              "      <td>0.000066</td>\n",
              "      <td>0.003550</td>\n",
              "      <td>0.000072</td>\n",
              "      <td>17</td>\n",
              "      <td>{'n_neighbors': 17}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.784275</td>\n",
              "      <td>0.055082</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.001379</td>\n",
              "      <td>0.000023</td>\n",
              "      <td>0.003617</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>19</td>\n",
              "      <td>{'n_neighbors': 19}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.779623</td>\n",
              "      <td>0.057292</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.001432</td>\n",
              "      <td>0.000147</td>\n",
              "      <td>0.003640</td>\n",
              "      <td>0.000174</td>\n",
              "      <td>21</td>\n",
              "      <td>{'n_neighbors': 21}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.784219</td>\n",
              "      <td>0.060047</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.001382</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.003632</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>23</td>\n",
              "      <td>{'n_neighbors': 23}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.906977</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.784330</td>\n",
              "      <td>0.054754</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.001392</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>0.003651</td>\n",
              "      <td>0.000110</td>\n",
              "      <td>25</td>\n",
              "      <td>{'n_neighbors': 25}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.883721</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.779679</td>\n",
              "      <td>0.050917</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.001359</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.003643</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>27</td>\n",
              "      <td>{'n_neighbors': 27}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.772591</td>\n",
              "      <td>0.050086</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.001409</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.003808</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>29</td>\n",
              "      <td>{'n_neighbors': 29}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.777353</td>\n",
              "      <td>0.040206</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.001385</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.003848</td>\n",
              "      <td>0.000172</td>\n",
              "      <td>31</td>\n",
              "      <td>{'n_neighbors': 31}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.782004</td>\n",
              "      <td>0.035866</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.001513</td>\n",
              "      <td>0.000251</td>\n",
              "      <td>0.004198</td>\n",
              "      <td>0.000898</td>\n",
              "      <td>33</td>\n",
              "      <td>{'n_neighbors': 33}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.777298</td>\n",
              "      <td>0.036432</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.001400</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.003826</td>\n",
              "      <td>0.000153</td>\n",
              "      <td>35</td>\n",
              "      <td>{'n_neighbors': 35}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.777353</td>\n",
              "      <td>0.040206</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.001387</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>0.003926</td>\n",
              "      <td>0.000190</td>\n",
              "      <td>37</td>\n",
              "      <td>{'n_neighbors': 37}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.772702</td>\n",
              "      <td>0.036913</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.001429</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.004039</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>39</td>\n",
              "      <td>{'n_neighbors': 39}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.770377</td>\n",
              "      <td>0.039292</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.001436</td>\n",
              "      <td>0.000058</td>\n",
              "      <td>0.003974</td>\n",
              "      <td>0.000111</td>\n",
              "      <td>41</td>\n",
              "      <td>{'n_neighbors': 41}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.775028</td>\n",
              "      <td>0.047457</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.001399</td>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.003840</td>\n",
              "      <td>0.000123</td>\n",
              "      <td>43</td>\n",
              "      <td>{'n_neighbors': 43}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.772702</td>\n",
              "      <td>0.047201</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.001371</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.003832</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>45</td>\n",
              "      <td>{'n_neighbors': 45}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.779790</td>\n",
              "      <td>0.036706</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.001417</td>\n",
              "      <td>0.000135</td>\n",
              "      <td>0.003849</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>47</td>\n",
              "      <td>{'n_neighbors': 47}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.772702</td>\n",
              "      <td>0.037054</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.001378</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.003988</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>49</td>\n",
              "      <td>{'n_neighbors': 49}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.772702</td>\n",
              "      <td>0.039867</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0        0.001619      0.000265  ...        0.073724               25\n",
              "1        0.001380      0.000049  ...        0.068279               24\n",
              "2        0.001391      0.000047  ...        0.045323               23\n",
              "3        0.001345      0.000015  ...        0.049578               22\n",
              "4        0.001401      0.000068  ...        0.040646               20\n",
              "5        0.001347      0.000017  ...        0.043944                1\n",
              "6        0.001385      0.000054  ...        0.053133                2\n",
              "7        0.001383      0.000041  ...        0.053187                3\n",
              "8        0.001376      0.000066  ...        0.055082                5\n",
              "9        0.001379      0.000023  ...        0.057292               10\n",
              "10       0.001432      0.000147  ...        0.060047                6\n",
              "11       0.001382      0.000060  ...        0.054754                4\n",
              "12       0.001392      0.000086  ...        0.050917                9\n",
              "13       0.001359      0.000013  ...        0.050086               19\n",
              "14       0.001409      0.000040  ...        0.040206               11\n",
              "15       0.001385      0.000034  ...        0.035866                7\n",
              "16       0.001513      0.000251  ...        0.036432               13\n",
              "17       0.001400      0.000029  ...        0.040206               11\n",
              "18       0.001387      0.000047  ...        0.036913               15\n",
              "19       0.001429      0.000051  ...        0.039292               20\n",
              "20       0.001436      0.000058  ...        0.047457               14\n",
              "21       0.001399      0.000103  ...        0.047201               15\n",
              "22       0.001371      0.000034  ...        0.036706                8\n",
              "23       0.001417      0.000135  ...        0.037054               15\n",
              "24       0.001378      0.000036  ...        0.039867               15\n",
              "\n",
              "[25 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=11, p=2,\n",
            "                     weights='uniform')\n",
            "Training result: 0.7985948477751756\n",
            "Test result: 0.7827102803738317\n",
            "Accuracy:\n",
            "Training result: 0.7985948477751756\n",
            "Test result: 0.7827102803738317\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO6550RrcGRd",
        "colab_type": "text"
      },
      "source": [
        "## KNN with Crossvalidation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1baCzMI2cKVq",
        "colab_type": "code",
        "outputId": "5001e385-72c5-4651-9991-dff8e4c7b488",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=20)\n",
        "results = []\n",
        "results_acc = []\n",
        "best_n_neighbors = []\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_pca, Y_train):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_pca[validation_index]\n",
        "    y_validation = np.array(Y_train)[validation_index]\n",
        "    \n",
        "    X_testKNN = X_train_pca[test_index]\n",
        "    y_testKNN = np.array(Y_train)[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_neighbors\": list(range(1, 26, 2))}\n",
        "    knn = neighbors.KNeighborsClassifier()\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "    grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_neighbors}')\n",
        "    best_n_neighbors.append(clf.n_neighbors)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_testKNN)\n",
        "    scores = probabilities[:, 1]\n",
        "\n",
        "    # Get the accuracy\n",
        "    y_pred = clf.predict(X_validation)\n",
        "    accuracy=metrics.accuracy_score(y_validation, y_pred)\n",
        "    results_acc.append({'acc': accuracy,'set': 'validation'})\n",
        "    y_pred = clf.predict(X_testKNN)\n",
        "    accuracy = metrics.accuracy_score(y_testKNN, y_pred)\n",
        "    results_acc.append({'acc': accuracy,'set': 'test'})\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_testKNN, scores)\n",
        "    results.append({'auc': auc,'k': clf.n_neighbors,'set': 'test'})\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "plt.show()\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "plt.show()\n",
        "results_acc = pd.DataFrame(results_acc)\n",
        "seaborn.boxplot(y='acc', x='set', data=results_acc)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "\n",
        "\n",
        "print(clf.score(X_test_pca, Y_test))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier: k=23\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=23\n",
            "Best classifier: k=23\n",
            "Best classifier: k=25\n",
            "Best classifier: k=23\n",
            "Best classifier: k=25\n",
            "Best classifier: k=23\n",
            "Best classifier: k=23\n",
            "Best classifier: k=23\n",
            "Best classifier: k=23\n",
            "Best classifier: k=15\n",
            "Best classifier: k=25\n",
            "Best classifier: k=15\n",
            "Best classifier: k=23\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntTIgJEmt/j9/VcljD9pw1gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The optimal N=23\n",
            "0.7780373831775701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9TA2vNS7f8v",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine (SVM) Classifier \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4v-fbsF7ueo",
        "colab_type": "code",
        "outputId": "39069ea2-fccf-4f9a-9d57-d3bbae495ad8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Construct classifiers and corresponding kernel (comment the ones that we do not want to use)\n",
        "\n",
        "# Linear kernel:\n",
        "svmlin = SVC(kernel='linear', gamma='scale')\n",
        "# Radial Basis Function (RBF) kernel:\n",
        "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
        "# Polynomial kernel:\n",
        "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
        "\n",
        "# Other options on kernels:\n",
        "# - change gamma\n",
        "# - sampler, for example: first use RBF sampler, then linear kernel\n",
        "# - manually constructed kernel function?\n",
        "# - precomputed kernel\n",
        "# - sigmoid kernel\n",
        "\n",
        "# Possibility: start with linear kernel and then gradually increase complexity\n",
        "clsfs = [svmlin, svmrbf, svmpoly]\n",
        "\n",
        "# Create lists of datasets to loop over (klopt dit?)\n",
        "\n",
        "Xs = X_train_pca\n",
        "Ys = Y_train\n",
        "\n",
        "# Important hyperparameters in SVM:\n",
        "# - degree of the kernel\n",
        "# - coef0s\n",
        "# - slacks\n",
        "\n",
        "# Tune hyperparameters (for now just a couple of examples)\n",
        "degrees = [1, 3, 5] # degree of the kernel (d) \n",
        "coef0s = [0.01, 0.5, 1] # the homogeneity of the kernel (c)\n",
        "slacks = [0.01, 0.5, 1] # slack parameter (C)\n",
        "    \n",
        "clsfs = list() \n",
        "for degree in degrees:\n",
        "    for coef0 in coef0s:\n",
        "        for slack in slacks:\n",
        "            clsfs.append(SVC(kernel='linear', degree=degree, coef0=coef0, C=slack, gamma='scale'))\n",
        "\n",
        "\n",
        "# Now use the classifier on all data\n",
        "for clsf in clsfs:\n",
        "  clsf.fit(Xs, Ys)\n",
        "  y_pred = clsf.predict(Xs)\n",
        "  print(f\"kernel: {clsf.kernel}\")\n",
        "  print(f\"degree: {clsf.degree}, coef0: {clsf.coef0}, C: {clsf.C}. \")\n",
        "  print(\"Misclassified: %d / %d\" % ((Ys != y_pred).sum(), Xs.shape[0]))\n",
        "  #ax = fig.add_subplot(clsf + 1, 3, num + 1)\n",
        "  #ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
        "             #s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
        "  #colorplot(clsf, ax, X[:, 0], X[:, 1]) \n",
        "  #ax.set_title(t)\n",
        "  #num += 1\n",
        "\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kernel: linear\n",
            "degree: 1, coef0: 0.01, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.01, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.01, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.5, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.5, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.5, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 1, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 1, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 1, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.01, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.01, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.01, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.5, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.5, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.5, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 1, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 1, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 1, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.01, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.01, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.01, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.5, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.5, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.5, C: 1. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 1, C: 0.01. \n",
            "Misclassified: 56 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 1, C: 0.5. \n",
            "Misclassified: 52 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 1, C: 1. \n",
            "Misclassified: 52 / 427\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}