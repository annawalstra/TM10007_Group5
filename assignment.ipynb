{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment Group 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nMZZV417dWs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "c2baa211-2ec6-462d-dd37-f6fe836583a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/annawalstra/tm10007_Group5.git\n",
        "!pip install simpleITK"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: simpleITK in /usr/local/lib/python3.6/dist-packages (1.2.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9m4YpjyWu6",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "695c6809-dc94-4a87-d4af-6207bf1aabb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition\n",
        "# Too learn more about metrics see: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "\n",
        "# Data loading functions. Uncomment the one you want to use\n",
        "from adni.load_data import load_data\n",
        "data = load_data()\n",
        "print(f'The number of spamples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Creating X and Y \n",
        "X = data.loc[:, data.columns != 'label']\n",
        "Y = data['label']\n",
        "\n",
        "# Preprocessing: deleting features with only zeros\n",
        "X = X.loc[:, (X != 0).any(axis=0)]\n",
        "# print(f'The number of spamples: {len(X.index)}')\n",
        "# print(f'The number of columns: {len(X.columns)}')\n",
        "\n",
        "# Binarize Y labels\n",
        "y_bin = preprocessing.label_binarize(Y, ['CN','AD'])\n",
        "y_bin = [i[0] for i in y_bin]\n",
        "#print(y_bin)\n",
        "\n",
        "# Split the dataset in train and test part\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y_bin, test_size=0.5, stratify=y_bin)\n",
        "\n",
        "\n",
        "# Scale the data \n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#Fitting the PCA algorithm with our Data\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA().fit(X_train_scaled)\n",
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)') #for each component\n",
        "plt.title('Dataset Explained Variance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Perform a PCA\n",
        "pca = decomposition.PCA(n_components=50)\n",
        "pca.fit(X_train_scaled)\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of spamples: 855\n",
            "The number of columns: 268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nwVEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgtMEyyJb6BZ",
        "colab_type": "text"
      },
      "source": [
        "## KNN Classifier\n",
        "\n",
        "Vraag: met grid_search.best_estimator_ krijg ik als het beste resultaat k=33, maar als ik k=25 invul krijg ik een hoger resultaat voor test en train. \n",
        "\n",
        "vgm snap ik dit nu wel...Soms grid_search.best_estimator_ ander resultaat voor beste k dan clf.n_neigbors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N-xw5GccCNu",
        "colab_type": "code",
        "outputId": "ba4f58e4-7c8d-41f9-d2fa-9ac0f340905e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "# Specify the classifier\n",
        "knn = neighbors.KNeighborsClassifier()\n",
        "parameters = {\"n_neighbors\": list(range(1, 51, 2))}\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='accuracy')\n",
        "grid_search.fit(X_train_pca, Y_train)\n",
        "# Show the complete results of the cross validation\n",
        "display(pd.DataFrame(grid_search.cv_results_))\n",
        "\n",
        "\n",
        "# # Fit kNN\n",
        "# Get resulting classifier\n",
        "print(grid_search.best_estimator_)\n",
        "#print(f'Best classifier: k={clf.n_neighbors}')\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors=21)\n",
        "clf.fit(X_train_pca, Y_train)\n",
        "score_train = clf.score(X_train_pca, Y_train)\n",
        "score_test = clf.score(X_test_pca, Y_test)\n",
        "\n",
        "# Get the accuracy\n",
        "y_pred = clf.predict(X_train_pca)\n",
        "acc_train=metrics.accuracy_score(Y_train, y_pred)\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "acc_test=metrics.accuracy_score(Y_test, y_pred)\n",
        "\n",
        "# Print result\n",
        "print(f\"Training result: {score_train}\")\n",
        "print(f\"Test result: {score_test}\")\n",
        "print(f\"Accuracy:\")\n",
        "print(f\"Training result: {acc_train}\")\n",
        "print(f\"Test result: {acc_test}\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_neighbors</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001997</td>\n",
              "      <td>0.001711</td>\n",
              "      <td>0.003516</td>\n",
              "      <td>0.000674</td>\n",
              "      <td>1</td>\n",
              "      <td>{'n_neighbors': 1}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.523810</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.690532</td>\n",
              "      <td>0.079030</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.000085</td>\n",
              "      <td>0.003362</td>\n",
              "      <td>0.000270</td>\n",
              "      <td>3</td>\n",
              "      <td>{'n_neighbors': 3}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.595238</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.642857</td>\n",
              "      <td>0.721152</td>\n",
              "      <td>0.071976</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001319</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.003239</td>\n",
              "      <td>0.000062</td>\n",
              "      <td>5</td>\n",
              "      <td>{'n_neighbors': 5}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.739978</td>\n",
              "      <td>0.056398</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001323</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.003274</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>7</td>\n",
              "      <td>{'n_neighbors': 7}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.765615</td>\n",
              "      <td>0.050349</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001394</td>\n",
              "      <td>0.000155</td>\n",
              "      <td>0.003385</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>9</td>\n",
              "      <td>{'n_neighbors': 9}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.765615</td>\n",
              "      <td>0.052503</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.001369</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>0.003530</td>\n",
              "      <td>0.000163</td>\n",
              "      <td>11</td>\n",
              "      <td>{'n_neighbors': 11}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.770377</td>\n",
              "      <td>0.047710</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.001360</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.003614</td>\n",
              "      <td>0.000047</td>\n",
              "      <td>13</td>\n",
              "      <td>{'n_neighbors': 13}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.767996</td>\n",
              "      <td>0.049548</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.001343</td>\n",
              "      <td>0.000049</td>\n",
              "      <td>0.003455</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>15</td>\n",
              "      <td>{'n_neighbors': 15}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.772757</td>\n",
              "      <td>0.058219</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001312</td>\n",
              "      <td>0.000013</td>\n",
              "      <td>0.003437</td>\n",
              "      <td>0.000068</td>\n",
              "      <td>17</td>\n",
              "      <td>{'n_neighbors': 17}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.779845</td>\n",
              "      <td>0.054036</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.001328</td>\n",
              "      <td>0.000051</td>\n",
              "      <td>0.003421</td>\n",
              "      <td>0.000055</td>\n",
              "      <td>19</td>\n",
              "      <td>{'n_neighbors': 19}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.789147</td>\n",
              "      <td>0.055093</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.001362</td>\n",
              "      <td>0.000091</td>\n",
              "      <td>0.003649</td>\n",
              "      <td>0.000483</td>\n",
              "      <td>21</td>\n",
              "      <td>{'n_neighbors': 21}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.775138</td>\n",
              "      <td>0.056139</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.001454</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>0.004071</td>\n",
              "      <td>0.000485</td>\n",
              "      <td>23</td>\n",
              "      <td>{'n_neighbors': 23}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.775138</td>\n",
              "      <td>0.057095</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.001455</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>0.003850</td>\n",
              "      <td>0.000584</td>\n",
              "      <td>25</td>\n",
              "      <td>{'n_neighbors': 25}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.779790</td>\n",
              "      <td>0.057225</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.001347</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.003568</td>\n",
              "      <td>0.000057</td>\n",
              "      <td>27</td>\n",
              "      <td>{'n_neighbors': 27}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.777464</td>\n",
              "      <td>0.054297</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.001374</td>\n",
              "      <td>0.000070</td>\n",
              "      <td>0.003756</td>\n",
              "      <td>0.000144</td>\n",
              "      <td>29</td>\n",
              "      <td>{'n_neighbors': 29}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.768106</td>\n",
              "      <td>0.047895</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.001341</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.003815</td>\n",
              "      <td>0.000064</td>\n",
              "      <td>31</td>\n",
              "      <td>{'n_neighbors': 31}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.768051</td>\n",
              "      <td>0.056603</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.001358</td>\n",
              "      <td>0.000030</td>\n",
              "      <td>0.003811</td>\n",
              "      <td>0.000038</td>\n",
              "      <td>33</td>\n",
              "      <td>{'n_neighbors': 33}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.772813</td>\n",
              "      <td>0.064042</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.001438</td>\n",
              "      <td>0.000232</td>\n",
              "      <td>0.004454</td>\n",
              "      <td>0.001008</td>\n",
              "      <td>35</td>\n",
              "      <td>{'n_neighbors': 35}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.772813</td>\n",
              "      <td>0.064881</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.001365</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.003937</td>\n",
              "      <td>0.000257</td>\n",
              "      <td>37</td>\n",
              "      <td>{'n_neighbors': 37}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.770487</td>\n",
              "      <td>0.063772</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.001317</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.003633</td>\n",
              "      <td>0.000067</td>\n",
              "      <td>39</td>\n",
              "      <td>{'n_neighbors': 39}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.768106</td>\n",
              "      <td>0.063440</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.001341</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.003826</td>\n",
              "      <td>0.000151</td>\n",
              "      <td>41</td>\n",
              "      <td>{'n_neighbors': 41}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.775138</td>\n",
              "      <td>0.069873</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.001391</td>\n",
              "      <td>0.000052</td>\n",
              "      <td>0.004001</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>43</td>\n",
              "      <td>{'n_neighbors': 43}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.763455</td>\n",
              "      <td>0.065004</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.001334</td>\n",
              "      <td>0.000020</td>\n",
              "      <td>0.003782</td>\n",
              "      <td>0.000164</td>\n",
              "      <td>45</td>\n",
              "      <td>{'n_neighbors': 45}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.756423</td>\n",
              "      <td>0.062320</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.001323</td>\n",
              "      <td>0.000024</td>\n",
              "      <td>0.003670</td>\n",
              "      <td>0.000056</td>\n",
              "      <td>47</td>\n",
              "      <td>{'n_neighbors': 47}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.761074</td>\n",
              "      <td>0.067122</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.001315</td>\n",
              "      <td>0.000010</td>\n",
              "      <td>0.003728</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>49</td>\n",
              "      <td>{'n_neighbors': 49}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.690476</td>\n",
              "      <td>0.761019</td>\n",
              "      <td>0.054759</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0        0.001997      0.001711  ...        0.079030               25\n",
              "1        0.001362      0.000085  ...        0.071976               24\n",
              "2        0.001319      0.000010  ...        0.056398               23\n",
              "3        0.001323      0.000024  ...        0.050349               17\n",
              "4        0.001394      0.000155  ...        0.052503               17\n",
              "5        0.001369      0.000055  ...        0.047710               12\n",
              "6        0.001360      0.000030  ...        0.049548               16\n",
              "7        0.001343      0.000049  ...        0.058219               10\n",
              "8        0.001312      0.000013  ...        0.054036                2\n",
              "9        0.001328      0.000051  ...        0.055093                1\n",
              "10       0.001362      0.000091  ...        0.056139                5\n",
              "11       0.001454      0.000120  ...        0.057095                5\n",
              "12       0.001455      0.000238  ...        0.057225                3\n",
              "13       0.001347      0.000024  ...        0.054297                4\n",
              "14       0.001374      0.000070  ...        0.047895               13\n",
              "15       0.001341      0.000005  ...        0.056603               15\n",
              "16       0.001358      0.000030  ...        0.064042                8\n",
              "17       0.001438      0.000232  ...        0.064881                8\n",
              "18       0.001365      0.000043  ...        0.063772               11\n",
              "19       0.001317      0.000020  ...        0.063440               13\n",
              "20       0.001341      0.000033  ...        0.069873                5\n",
              "21       0.001391      0.000052  ...        0.065004               19\n",
              "22       0.001334      0.000020  ...        0.062320               22\n",
              "23       0.001323      0.000024  ...        0.067122               20\n",
              "24       0.001315      0.000010  ...        0.054759               21\n",
              "\n",
              "[25 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=19, p=2,\n",
            "                     weights='uniform')\n",
            "Training result: 0.8056206088992974\n",
            "Test result: 0.7873831775700935\n",
            "Accuracy:\n",
            "Training result: 0.8056206088992974\n",
            "Test result: 0.7873831775700935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO6550RrcGRd",
        "colab_type": "text"
      },
      "source": [
        "## KNN with Crossvalidation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1baCzMI2cKVq",
        "colab_type": "code",
        "outputId": "2fb5321c-0e27-44db-925d-089489000e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        }
      },
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=20)\n",
        "results = []\n",
        "results_acc = []\n",
        "best_n_neighbors = []\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_pca, Y_train):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_pca[validation_index]\n",
        "    y_validation = np.array(Y_train)[validation_index]\n",
        "    \n",
        "    X_testKNN = X_train_pca[test_index]\n",
        "    y_testKNN = np.array(Y_train)[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_neighbors\": list(range(1, 26, 2))}\n",
        "    knn = neighbors.KNeighborsClassifier()\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "    grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_neighbors}')\n",
        "    best_n_neighbors.append(clf.n_neighbors)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_testKNN)\n",
        "    scores = probabilities[:, 1]\n",
        "\n",
        "    # Get the accuracy\n",
        "    y_pred = clf.predict(X_validation)\n",
        "    accuracy=metrics.accuracy_score(y_validation, y_pred)\n",
        "    results_acc.append({'acc': accuracy,'set': 'validation'})\n",
        "    y_pred = clf.predict(X_testKNN)\n",
        "    accuracy = metrics.accuracy_score(y_testKNN, y_pred)\n",
        "    results_acc.append({'acc': accuracy,'set': 'test'})\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_testKNN, scores)\n",
        "    results.append({'auc': auc,'k': clf.n_neighbors,'set': 'test'})\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "plt.show()\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "plt.show()\n",
        "results_acc = pd.DataFrame(results_acc)\n",
        "seaborn.boxplot(y='acc', x='set', data=results_acc)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "\n",
        "\n",
        "print(clf.score(X_test_pca, Y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier: k=17\n",
            "Best classifier: k=17\n",
            "Best classifier: k=17\n",
            "Best classifier: k=17\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=13\n",
            "Best classifier: k=15\n",
            "Best classifier: k=19\n",
            "Best classifier: k=15\n",
            "Best classifier: k=15\n",
            "Best classifier: k=19\n",
            "Best classifier: k=19\n",
            "Best classifier: k=17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJElNBoQkqcmAkCQ1GRCSpCYDQpLU9P8BO83inqTYcNIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The optimal N=15\n",
            "0.7920560747663551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9TA2vNS7f8v",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine (SVM) Classifier \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4v-fbsF7ueo",
        "colab_type": "code",
        "outputId": "23a52016-3b55-4d0b-c186-e1475fda5b06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Construct classifiers and corresponding kernel (comment the ones that we do not want to use)\n",
        "\n",
        "# Linear kernel:\n",
        "svmlin = SVC(kernel='linear', gamma='scale')\n",
        "# Radial Basis Function (RBF) kernel:\n",
        "svmrbf = SVC(kernel='rbf', gamma='scale')\n",
        "# Polynomial kernel:\n",
        "svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
        "\n",
        "# Other options on kernels:\n",
        "# - change gamma\n",
        "# - sampler, for example: first use RBF sampler, then linear kernel\n",
        "# - manually constructed kernel function?\n",
        "# - precomputed kernel\n",
        "# - sigmoid kernel\n",
        "\n",
        "# Possibility: start with linear kernel and then gradually increase complexity\n",
        "clsfs = [svmlin, svmrbf, svmpoly]\n",
        "\n",
        "# Create lists of datasets to loop over (klopt dit?)\n",
        "\n",
        "Xs = X_train_pca\n",
        "Ys = Y_train\n",
        "\n",
        "# Important hyperparameters in SVM:\n",
        "# - degree of the kernel\n",
        "# - coef0s\n",
        "# - slacks\n",
        "\n",
        "# Tune hyperparameters (for now just a couple of examples)\n",
        "degrees = [1, 3, 5] # degree of the kernel (d) \n",
        "coef0s = [0.01, 0.5, 1] # the homogeneity of the kernel (c)\n",
        "slacks = [0.01, 0.5, 1] # slack parameter (C)\n",
        "    \n",
        "clsfs = list() \n",
        "for degree in degrees:\n",
        "    for coef0 in coef0s:\n",
        "        for slack in slacks:\n",
        "            clsfs.append(SVC(kernel='linear', degree=degree, coef0=coef0, C=slack, gamma='scale'))\n",
        "\n",
        "\n",
        "# Now use the classifier on all data\n",
        "for clsf in clsfs:\n",
        "  clsf.fit(Xs, Ys)\n",
        "  y_pred = clsf.predict(Xs)\n",
        "  print(f\"kernel: {clsf.kernel}\")\n",
        "  print(f\"degree: {clsf.degree}, coef0: {clsf.coef0}, C: {clsf.C}. \")\n",
        "  print(\"Misclassified: %d / %d\" % ((Ys != y_pred).sum(), Xs.shape[0]))\n",
        "  #ax = fig.add_subplot(clsf + 1, 3, num + 1)\n",
        "  #ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
        "             #s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
        "  #colorplot(clsf, ax, X[:, 0], X[:, 1]) \n",
        "  #ax.set_title(t)\n",
        "  #num += 1\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kernel: linear\n",
            "degree: 1, coef0: 0.01, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.01, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.01, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.5, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.5, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 0.5, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 1, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 1, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 1, coef0: 1, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.01, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.01, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.01, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.5, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.5, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 0.5, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 1, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 1, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 3, coef0: 1, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.01, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.01, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.01, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.5, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.5, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 0.5, C: 1. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 1, C: 0.01. \n",
            "Misclassified: 68 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 1, C: 0.5. \n",
            "Misclassified: 57 / 427\n",
            "kernel: linear\n",
            "degree: 5, coef0: 1, C: 1. \n",
            "Misclassified: 57 / 427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3VeeVBm_Bbo",
        "colab_type": "text"
      },
      "source": [
        "**Random Forrest Classifier**\n",
        "\n",
        "The Random Forrest Classifier has 19 different hyperparameters:\n",
        "- n_estimators: number of trees (to much --> overfitting)\n",
        "- criterion: How to measure the quality of a split (gini) (tree-specific)\n",
        "- max_depth: depth of the tree\n",
        "- min_samples_split: minimum number of samples required to split an internal node\n",
        "- min_samples_leaf: number of samples required to be at a node\n",
        "- min_weight_fraction_leaf: sum total of the weigths at a node.\n",
        "- max_features: number of features to consider\n",
        "- max_leaf_nodes: \n",
        "- min_impurity_decrease: node will split if impurity decreases with this value\n",
        "- min_impurity_split: A node will split if its impurity is above the threshold, otherwise it is a leaf\n",
        "- bootstrap: use or not (T/F) (To improve accuracy by creating samples)\n",
        "if T --> max_samples: number of samples to train each base estimator\n",
        "- oob_score: use out-of-bag samples\n",
        "- n_jobs: \n",
        "- random_state: \n",
        "- verbose:\n",
        "- warm_start:\n",
        "- class_weight: If one class is more important\n",
        "- ccp_alpha: x\n",
        "\n",
        "--> Misschien toevoegen: een tijd segment om te kijken of het niet te lang duurt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkxtQjuq-_i0",
        "colab_type": "code",
        "outputId": "9e04de75-5cf7-44bf-cc5c-178f36cc6975",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Hyperparameters tuning:\n",
        "n_tree = [10,25,50,100]  # n_estimators\n",
        "boot = ['True','False']  # Bootstrapping\n",
        "criterion = ['gini','entropy'] # measure of quality\n",
        "max_depth = [range(5, 16)] # Depth of the tree\n",
        "min_samples_split = [range(2,7)] # prevends overfitting\n",
        "min_samples_leaf = [1,2] # prevends overfitting\n",
        "classweight = [{0: 1, 1: 0.001},{0: 1, 1: 1},\n",
        "               {0: 1, 1: 10},{0: 1, 1: 100}]\n",
        "\n",
        "\n",
        "clsfs = [n_tree, boot, criterion, max_depth, min_samples_split, \n",
        "         min_samples_leaf, classweight]\n",
        "\n",
        "\n",
        "# Y_test = validation set, niet de test set\n",
        "for clf in clsfs:\n",
        "  for hype_par in clf:\n",
        "    for X, Y in zip(Xtrain,Ytrain):\n",
        "      clf.fit(X, Y)\n",
        "      y_pred_train = clf.predict(X_train_pca)\n",
        "      acc_train = metrics.accuracy_score(Y_train, y_pred)\n",
        "      y_pred_test = clf.predict(X_test_pca)\n",
        "      acc_test = metrics.accuracy_score(Y_test, y_pred)\n",
        "      acc_test_clsfs.append(acc_test)\n",
        "    maxpos = acc.index(max(acc_test_clsfs))\n",
        "  # hier moet nog dat het die plek van deze classifier is \n",
        "\n",
        "clsfs_final = [RandomForestClassifier(n_estimators = n_tree(n_tree[maxpos]))]\n",
        "\n",
        "# First make plot without classifiers:\n",
        "num = 0\n",
        "fig = plt.figure(figsize=(24,8*len(clsfs)))\n",
        "for X, Y in zip(Xs, Ys):\n",
        "    ax = fig.add_subplot(7, 3, num + 1)\n",
        "    ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
        "        s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
        "    num += 1\n",
        "    \n",
        "# Now use the classifiers on all datasets\n",
        "for clf in clsfs:\n",
        "    for X, Y in zip(Xs, Ys):\n",
        "        clf.fit(X, Y)\n",
        "        ax = fig.add_subplot(7, 3, num + 1)\n",
        "        ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
        "            s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
        "        colorplot(clf, ax, X[:, 0], X[:, 1])\n",
        "        y_pred = clf.predict(X)\n",
        "        t = (\"Misclassified: %d / %d\" % ((Y != y_pred).sum(), X.shape[0]))\n",
        "        ax.set_title(t)\n",
        "        num += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OF9D8tov5dlz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}