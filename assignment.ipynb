{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7SXpaKwwGe5x"
      },
      "source": [
        "# TM10007 Assignment Group 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CiDn2Sk-VWqE",
        "outputId": "8b267f81-1b4a-438e-d623-9a02d3a22b0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "source": [
        "# Run this to use from colab environment\n",
        "!pip install -q --upgrade git+https://github.com/annawalstra/tm10007_Group5.git\n",
        "!pip install simpleITK"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for brats (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting simpleITK\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 116kB/s \n",
            "\u001b[?25hInstalling collected packages: simpleITK\n",
            "Successfully installed simpleITK-1.2.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WK9m4YpjyWu6",
        "colab_type": "text"
      },
      "source": [
        "## Data loading and cleaning\n",
        "\n",
        "Below are functions to load the dataset of your choice. After that, it is all up to you to create and evaluate a classification method. Beware, there may be missing values in these datasets. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-J7kksF-ZT",
        "colab_type": "text"
      },
      "source": [
        "Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-NE_fTbKGe5z",
        "outputId": "a9826016-5f41-4c9d-9e2d-81ffee5857f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        }
      },
      "source": [
        "# General packages\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets as ds\n",
        "import seaborn\n",
        "import SimpleITK as sitk\n",
        "\n",
        "# Classifiers\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn import feature_selection \n",
        "from sklearn import preprocessing\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import decomposition\n",
        "\n",
        "# Classifiers and kernels\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.decomposition import PCA, KernelPCA\n",
        "from sklearn.kernel_approximation import RBFSampler\n",
        "from sklearn.metrics.pairwise import rbf_kernel, sigmoid_kernel\n",
        "\n",
        "\n",
        "# To learn more about metrics see: https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "\n",
        "# Data loading functions. Uncomment the one you want to use\n",
        "from adni.load_data import load_data\n",
        "data = load_data()\n",
        "print(f'The number of spamples: {len(data.index)}')\n",
        "print(f'The number of columns: {len(data.columns)}')\n",
        "\n",
        "# Creating X and Y \n",
        "X = data.loc[:, data.columns != 'label']\n",
        "Y = data['label']\n",
        "\n",
        "# Preprocessing: deleting features with only zeros\n",
        "X = X.loc[:, (X != 0).any(axis=0)]\n",
        "# print(f'The number of spamples: {len(X.index)}')\n",
        "# print(f'The number of columns: {len(X.columns)}')\n",
        "\n",
        "# Binarize Y labels\n",
        "y_bin = preprocessing.label_binarize(Y, ['CN','AD'])\n",
        "y_bin = [i[0] for i in y_bin]\n",
        "#print(y_bin)\n",
        "\n",
        "# Split the dataset in train and test part\n",
        "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, y_bin, test_size=0.5, stratify=y_bin)\n",
        "\n",
        "\n",
        "# Scale the data \n",
        "scaler = preprocessing.StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train_scaled = scaler.transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "#Fitting the PCA algorithm with our Data\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA().fit(X_train_scaled)\n",
        "#Plotting the Cumulative Summation of the Explained Variance\n",
        "plt.figure()\n",
        "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Variance (%)') #for each component\n",
        "plt.title('Dataset Explained Variance')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Perform a PCA\n",
        "pca = decomposition.PCA(n_components=50)\n",
        "pca.fit(X_train_scaled)\n",
        "X_train_pca = pca.transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of spamples: 855\n",
            "The number of columns: 268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmJnlOScCM7M850RgZpbn/j/i88tgQARUBwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgtMEyyJb6BZ",
        "colab_type": "text"
      },
      "source": [
        "## KNN Classifier\n",
        "\n",
        "Vraag: met grid_search.best_estimator_ krijg ik als het beste resultaat k=33, maar als ik k=25 invul krijg ik een hoger resultaat voor test en train. \n",
        "\n",
        "vgm snap ik dit nu wel...Soms grid_search.best_estimator_ ander resultaat voor beste k dan clf.n_neigbors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6N-xw5GccCNu",
        "colab_type": "code",
        "outputId": "304ab11f-e346-4c13-ca2f-69085695712d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "# Specify the classifier\n",
        "knn = neighbors.KNeighborsClassifier()\n",
        "parameters = {\"n_neighbors\": list(range(1, 51, 2))}\n",
        "cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='accuracy')\n",
        "grid_search.fit(X_train_pca, Y_train)\n",
        "# Show the complete results of the cross validation\n",
        "display(pd.DataFrame(grid_search.cv_results_))\n",
        "\n",
        "\n",
        "# # Fit kNN\n",
        "# Get resulting classifier\n",
        "print(grid_search.best_estimator_)\n",
        "#print(f'Best classifier: k={clf.n_neighbors}')\n",
        "clf = neighbors.KNeighborsClassifier(n_neighbors=21)\n",
        "clf.fit(X_train_pca, Y_train)\n",
        "score_train = clf.score(X_train_pca, Y_train)\n",
        "score_test = clf.score(X_test_pca, Y_test)\n",
        "\n",
        "# Get the accuracy\n",
        "y_pred = clf.predict(X_train_pca)\n",
        "acc_train=metrics.accuracy_score(Y_train, y_pred)\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "acc_test=metrics.accuracy_score(Y_test, y_pred)\n",
        "\n",
        "# Print result\n",
        "print(f\"Training result: {score_train}\")\n",
        "print(f\"Test result: {score_test}\")\n",
        "print(f\"Accuracy:\")\n",
        "print(f\"Training result: {acc_train}\")\n",
        "print(f\"Test result: {acc_test}\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_neighbors</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>split3_test_score</th>\n",
              "      <th>split4_test_score</th>\n",
              "      <th>split5_test_score</th>\n",
              "      <th>split6_test_score</th>\n",
              "      <th>split7_test_score</th>\n",
              "      <th>split8_test_score</th>\n",
              "      <th>split9_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.001931</td>\n",
              "      <td>0.001062</td>\n",
              "      <td>0.003776</td>\n",
              "      <td>0.000427</td>\n",
              "      <td>1</td>\n",
              "      <td>{'n_neighbors': 1}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.571429</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.619048</td>\n",
              "      <td>0.697508</td>\n",
              "      <td>0.069348</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.001712</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>0.003933</td>\n",
              "      <td>0.000679</td>\n",
              "      <td>3</td>\n",
              "      <td>{'n_neighbors': 3}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.730897</td>\n",
              "      <td>0.060134</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001440</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.003645</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>5</td>\n",
              "      <td>{'n_neighbors': 5}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.809524</td>\n",
              "      <td>0.744795</td>\n",
              "      <td>0.061171</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.000060</td>\n",
              "      <td>0.003589</td>\n",
              "      <td>0.000196</td>\n",
              "      <td>7</td>\n",
              "      <td>{'n_neighbors': 7}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.780233</td>\n",
              "      <td>0.073987</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.001468</td>\n",
              "      <td>0.000026</td>\n",
              "      <td>0.003662</td>\n",
              "      <td>0.000105</td>\n",
              "      <td>9</td>\n",
              "      <td>{'n_neighbors': 9}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.775471</td>\n",
              "      <td>0.066093</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.001448</td>\n",
              "      <td>0.000107</td>\n",
              "      <td>0.003640</td>\n",
              "      <td>0.000266</td>\n",
              "      <td>11</td>\n",
              "      <td>{'n_neighbors': 11}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.768328</td>\n",
              "      <td>0.052139</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.001401</td>\n",
              "      <td>0.000029</td>\n",
              "      <td>0.003583</td>\n",
              "      <td>0.000127</td>\n",
              "      <td>13</td>\n",
              "      <td>{'n_neighbors': 13}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.773200</td>\n",
              "      <td>0.063553</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.001590</td>\n",
              "      <td>0.000636</td>\n",
              "      <td>0.003574</td>\n",
              "      <td>0.000138</td>\n",
              "      <td>15</td>\n",
              "      <td>{'n_neighbors': 15}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.627907</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.763843</td>\n",
              "      <td>0.072686</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.001456</td>\n",
              "      <td>0.000160</td>\n",
              "      <td>0.003706</td>\n",
              "      <td>0.000157</td>\n",
              "      <td>17</td>\n",
              "      <td>{'n_neighbors': 17}</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.768383</td>\n",
              "      <td>0.056062</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.001471</td>\n",
              "      <td>0.000199</td>\n",
              "      <td>0.003784</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>19</td>\n",
              "      <td>{'n_neighbors': 19}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.773090</td>\n",
              "      <td>0.053492</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.001537</td>\n",
              "      <td>0.000226</td>\n",
              "      <td>0.003787</td>\n",
              "      <td>0.000211</td>\n",
              "      <td>21</td>\n",
              "      <td>{'n_neighbors': 21}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.775471</td>\n",
              "      <td>0.053617</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.001419</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>0.003757</td>\n",
              "      <td>0.000120</td>\n",
              "      <td>23</td>\n",
              "      <td>{'n_neighbors': 23}</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.775471</td>\n",
              "      <td>0.059362</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.001398</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.003708</td>\n",
              "      <td>0.000119</td>\n",
              "      <td>25</td>\n",
              "      <td>{'n_neighbors': 25}</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.770764</td>\n",
              "      <td>0.061658</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.001404</td>\n",
              "      <td>0.000033</td>\n",
              "      <td>0.003788</td>\n",
              "      <td>0.000238</td>\n",
              "      <td>27</td>\n",
              "      <td>{'n_neighbors': 27}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.766168</td>\n",
              "      <td>0.056161</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.001420</td>\n",
              "      <td>0.000048</td>\n",
              "      <td>0.003890</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>29</td>\n",
              "      <td>{'n_neighbors': 29}</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.770819</td>\n",
              "      <td>0.061589</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.001434</td>\n",
              "      <td>0.000054</td>\n",
              "      <td>0.003826</td>\n",
              "      <td>0.000102</td>\n",
              "      <td>31</td>\n",
              "      <td>{'n_neighbors': 31}</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.784828</td>\n",
              "      <td>0.066880</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.001430</td>\n",
              "      <td>0.000073</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.000173</td>\n",
              "      <td>33</td>\n",
              "      <td>{'n_neighbors': 33}</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.777907</td>\n",
              "      <td>0.066078</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.001399</td>\n",
              "      <td>0.000043</td>\n",
              "      <td>0.003857</td>\n",
              "      <td>0.000131</td>\n",
              "      <td>35</td>\n",
              "      <td>{'n_neighbors': 35}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.777741</td>\n",
              "      <td>0.061580</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.001437</td>\n",
              "      <td>0.000098</td>\n",
              "      <td>0.003983</td>\n",
              "      <td>0.000250</td>\n",
              "      <td>37</td>\n",
              "      <td>{'n_neighbors': 37}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.837209</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.775415</td>\n",
              "      <td>0.065736</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.001643</td>\n",
              "      <td>0.000487</td>\n",
              "      <td>0.004248</td>\n",
              "      <td>0.000835</td>\n",
              "      <td>39</td>\n",
              "      <td>{'n_neighbors': 39}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.768439</td>\n",
              "      <td>0.062427</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0.001402</td>\n",
              "      <td>0.000034</td>\n",
              "      <td>0.003889</td>\n",
              "      <td>0.000076</td>\n",
              "      <td>41</td>\n",
              "      <td>{'n_neighbors': 41}</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.768439</td>\n",
              "      <td>0.064974</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.001418</td>\n",
              "      <td>0.000045</td>\n",
              "      <td>0.003949</td>\n",
              "      <td>0.000093</td>\n",
              "      <td>43</td>\n",
              "      <td>{'n_neighbors': 43}</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.738095</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.763787</td>\n",
              "      <td>0.060309</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0.001394</td>\n",
              "      <td>0.000040</td>\n",
              "      <td>0.003871</td>\n",
              "      <td>0.000178</td>\n",
              "      <td>45</td>\n",
              "      <td>{'n_neighbors': 45}</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.880952</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.766224</td>\n",
              "      <td>0.066546</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.001444</td>\n",
              "      <td>0.000082</td>\n",
              "      <td>0.004144</td>\n",
              "      <td>0.000200</td>\n",
              "      <td>47</td>\n",
              "      <td>{'n_neighbors': 47}</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.763843</td>\n",
              "      <td>0.064416</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0.001438</td>\n",
              "      <td>0.000090</td>\n",
              "      <td>0.004104</td>\n",
              "      <td>0.000217</td>\n",
              "      <td>49</td>\n",
              "      <td>{'n_neighbors': 49}</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.651163</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.761905</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.833333</td>\n",
              "      <td>0.756866</td>\n",
              "      <td>0.066551</td>\n",
              "      <td>22</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0        0.001931      0.001062  ...        0.069348               25\n",
              "1        0.001712      0.000428  ...        0.060134               24\n",
              "2        0.001440      0.000034  ...        0.061171               23\n",
              "3        0.001418      0.000060  ...        0.073987                2\n",
              "4        0.001468      0.000026  ...        0.066093                5\n",
              "5        0.001448      0.000107  ...        0.052139               16\n",
              "6        0.001401      0.000029  ...        0.063553                9\n",
              "7        0.001590      0.000636  ...        0.072686               19\n",
              "8        0.001456      0.000160  ...        0.056062               15\n",
              "9        0.001471      0.000199  ...        0.053492               10\n",
              "10       0.001537      0.000226  ...        0.053617                5\n",
              "11       0.001419      0.000039  ...        0.059362                5\n",
              "12       0.001398      0.000018  ...        0.061658               12\n",
              "13       0.001404      0.000033  ...        0.056161               18\n",
              "14       0.001420      0.000048  ...        0.061589               11\n",
              "15       0.001434      0.000054  ...        0.066880                1\n",
              "16       0.001430      0.000073  ...        0.066078                3\n",
              "17       0.001399      0.000043  ...        0.061580                4\n",
              "18       0.001437      0.000098  ...        0.065736                8\n",
              "19       0.001643      0.000487  ...        0.062427               13\n",
              "20       0.001402      0.000034  ...        0.064974               13\n",
              "21       0.001418      0.000045  ...        0.060309               21\n",
              "22       0.001394      0.000040  ...        0.066546               17\n",
              "23       0.001444      0.000082  ...        0.064416               20\n",
              "24       0.001438      0.000090  ...        0.066551               22\n",
              "\n",
              "[25 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=None, n_neighbors=31, p=2,\n",
            "                     weights='uniform')\n",
            "Training result: 0.7728337236533958\n",
            "Test result: 0.794392523364486\n",
            "Accuracy:\n",
            "Training result: 0.7728337236533958\n",
            "Test result: 0.794392523364486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CO6550RrcGRd",
        "colab_type": "text"
      },
      "source": [
        "## KNN with Crossvalidation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1baCzMI2cKVq",
        "colab_type": "code",
        "outputId": "654116d4-396d-4fe7-e2ab-5c6e95438dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        }
      },
      "source": [
        "# Create a 20 fold stratified CV iterator\n",
        "cv_20fold = model_selection.StratifiedKFold(n_splits=20)\n",
        "results = []\n",
        "results_acc = []\n",
        "best_n_neighbors = []\n",
        "\n",
        "# Loop over the folds\n",
        "for validation_index, test_index in cv_20fold.split(X_train_pca, Y_train):\n",
        "    # Split the data properly\n",
        "    X_validation = X_train_pca[validation_index]\n",
        "    y_validation = np.array(Y_train)[validation_index]\n",
        "    \n",
        "    X_testKNN = X_train_pca[test_index]\n",
        "    y_testKNN = np.array(Y_train)[test_index]\n",
        "    \n",
        "    # Create a grid search to find the optimal k using a gridsearch and 10-fold cross validation\n",
        "    # Same as above\n",
        "    parameters = {\"n_neighbors\": list(range(1, 26, 2))}\n",
        "    knn = neighbors.KNeighborsClassifier()\n",
        "    cv_10fold = model_selection.StratifiedKFold(n_splits=10)\n",
        "    grid_search = model_selection.GridSearchCV(knn, parameters, cv=cv_10fold, scoring='roc_auc')\n",
        "    grid_search.fit(X_validation, y_validation)\n",
        "    \n",
        "    # Get resulting classifier\n",
        "    clf = grid_search.best_estimator_\n",
        "    print(f'Best classifier: k={clf.n_neighbors}')\n",
        "    best_n_neighbors.append(clf.n_neighbors)\n",
        "    \n",
        "    # Test the classifier on the test data\n",
        "    probabilities = clf.predict_proba(X_testKNN)\n",
        "    scores = probabilities[:, 1]\n",
        "\n",
        "    # Get the accuracy\n",
        "    y_pred = clf.predict(X_validation)\n",
        "    accuracy=metrics.accuracy_score(y_validation, y_pred)\n",
        "    results_acc.append({'acc': accuracy,'set': 'validation'})\n",
        "    y_pred = clf.predict(X_testKNN)\n",
        "    accuracy = metrics.accuracy_score(y_testKNN, y_pred)\n",
        "    results_acc.append({'acc': accuracy,'set': 'test'})\n",
        "    \n",
        "    # Get the auc\n",
        "    auc = metrics.roc_auc_score(y_testKNN, scores)\n",
        "    results.append({'auc': auc,'k': clf.n_neighbors,'set': 'test'})\n",
        "    \n",
        "    # Test the classifier on the validation data\n",
        "    probabilities_validation = clf.predict_proba(X_validation)\n",
        "    scores_validation = probabilities_validation[:, 1]\n",
        "    \n",
        "    # Get the auc\n",
        "    auc_validation = metrics.roc_auc_score(y_validation, scores_validation)\n",
        "    results.append({\n",
        "        'auc': auc_validation,\n",
        "        'k': clf.n_neighbors,\n",
        "        'set': 'validation'\n",
        "    })\n",
        "    \n",
        "# Create results dataframe and plot it\n",
        "results = pd.DataFrame(results)\n",
        "plt.show()\n",
        "seaborn.boxplot(y='auc', x='set', data=results)\n",
        "plt.show()\n",
        "results_acc = pd.DataFrame(results_acc)\n",
        "seaborn.boxplot(y='acc', x='set', data=results_acc)\n",
        "\n",
        "optimal_n = int(np.median(best_n_neighbors))\n",
        "print(f\"The optimal N={optimal_n}\")\n",
        "\n",
        "\n",
        "print(clf.score(X_test_pca, Y_test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=21\n",
            "Best classifier: k=25\n",
            "Best classifier: k=21\n",
            "Best classifier: k=25\n",
            "Best classifier: k=21\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=21\n",
            "Best classifier: k=21\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=23\n",
            "Best classifier: k=25\n",
            "Best classifier: k=21\n",
            "Best classifier: k=7\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n",
            "Best classifier: k=25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEHCAYAAAC0pdErAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngJAktTIgJEmtDAhJUqv/D2IB8QBCIu/5AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "The optimal N=25\n",
            "0.8037383177570093\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0KS1MqAkCS1MiAkSa0MCElSq/8PlojaSexHxmYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9TA2vNS7f8v",
        "colab_type": "text"
      },
      "source": [
        "# Support Vector Machine (SVM) Classifier \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4v-fbsF7ueo",
        "colab_type": "code",
        "outputId": "f70b11d4-2a15-4dd6-8d9d-809fa4e98217",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 585
        }
      },
      "source": [
        "# Construct classifiers and corresponding kernel (comment the ones that we do not want to use)\n",
        "# Start with linear kernel and then gradually increase complexity\n",
        "\n",
        "# Linear kernel:\n",
        "svmlin = SVC(kernel='linear', gamma='scale')\n",
        "# Radial Basis Function (RBF) kernel:\n",
        "#svmrbf = SVC(kernel='rbf', gamma='scale')\n",
        "# Polynomial kernel:\n",
        "#svmpoly = SVC(kernel='poly', degree=3, gamma='scale')\n",
        "\n",
        "# Other options on kernels:\n",
        "# - change gamma\n",
        "# - sampler, for example: first use RBF sampler, then linear kernel\n",
        "# - manually constructed kernel function?\n",
        "# - precomputed kernel\n",
        "# - sigmoid kernel\n",
        "\n",
        "clsf = svmlin\n",
        "\n",
        "# Create lists of datasets to loop over (klopt dit?)\n",
        "\n",
        "Xs = X_train_pca\n",
        "Ys = Y_train\n",
        "\n",
        "# Important hyperparameters in SVM:\n",
        "# - degree of the kernel\n",
        "# - coef0s\n",
        "# - slacks\n",
        "\n",
        "# Tune hyperparameters\n",
        "degree = 1 # degree of the kernel (d) \n",
        "coef0 = 0.01 # the homogeneity of the kernel (c)\n",
        "slack = 0.01 # slack parameter (C)\n",
        "    \n",
        "    \n",
        "# Now use the classifier on all data\n",
        "for X, Y in zip(Xs, Ys):\n",
        "  clsf.fit(X, Y)\n",
        "  clsf.append(SVC(kernel='linear', degree=degree, coef0=coef0, C=slack, gamma='scale'))\n",
        "  #ax = fig.add_subplot(clsf + 1, 3, num + 1)\n",
        "  #ax.scatter(X[:, 0], X[:, 1], marker='o', c=Y,\n",
        "             #s=25, edgecolor='k', cmap=plt.cm.Paired)\n",
        "  #colorplot(clsf, ax, X[:, 0], X[:, 1])\n",
        "  y_pred = clsf.predict(X)\n",
        "  print(f\"degree: {clsf.degree}, coef0: {clsf.coef0}, C: {clsf.C}. \")\n",
        "  print(\"Misclassified: %d / %d\" % ((Y != y_pred).sum(), X.shape[0])) \n",
        "  #ax.set_title(t)\n",
        "  #num += 1\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-68dfb1a19106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Now use the classifier on all data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m   \u001b[0mclsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m   \u001b[0mclsf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslack\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'scale'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0;31m#ax = fig.add_subplot(clsf + 1, 3, num + 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    554\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 556\u001b[0;31m                     \"if it contains a single sample.\".format(array))\n\u001b[0m\u001b[1;32m    557\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;31m# in the future np.flexible dtypes will be handled like object dtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 4.46340015  3.79582551 12.94691512  4.95661743 -3.78730793  2.03076386\n  9.9497581  -3.00788097  0.3229735  -0.78639158  1.39750733  0.27063445\n -3.71332481 -2.08454445 -0.2488842   2.23090052 -3.00659944  2.18653805\n  1.3294087  -0.76209713 -3.39521618  1.23318087  1.04015255  0.62052984\n  1.11045489 -1.43944689  2.93954184 -0.09048015  0.51849176  0.13049545\n  0.82402579  1.34149773 -0.06160917  0.49548103 -0.93035345 -0.08060748\n  0.28434113 -0.63863435  0.67713449  1.23183571  0.48747439 -0.93011256\n -0.27621532  1.30033035  0.38101024 -2.77341549  0.18982994  0.82412938\n  1.47832692 -0.96787337].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    }
  ]
}